{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41feefc5",
   "metadata": {},
   "source": [
    "# Scraping data from Indeed.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "244e4931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05341305",
   "metadata": {},
   "source": [
    "# setting the webdriver\n",
    "    to allow us to interact with the web browser page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc9a8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an intance ChromeOptions to configure various options for the driver\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "# add my user-agent to mimic the chrome webriver we created\n",
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36'\n",
    "options.add_argument(f'user_agent = {user_agent}')\n",
    "\n",
    "# setting the webdriver\n",
    "driver = webdriver.Chrome(options = options)\n",
    "\n",
    "\n",
    "\n",
    "# url of the website we want to scrape\n",
    "url = 'https://eg.indeed.com/jobs?q=data%20analyst&l=Cairo'\n",
    "\n",
    "# navigate the url using the driver to begin scraping\n",
    "driver.get(url)\n",
    "sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b1a623",
   "metadata": {},
   "source": [
    "# Using BeautifulSoup to parse the html source script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ef4841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the html source\n",
    "src = driver.page_source\n",
    "\n",
    "# parse it\n",
    "soup = BeautifulSoup(src, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4c9606",
   "metadata": {},
   "source": [
    "# extracting specific info\n",
    "    like:\n",
    "    - job title\n",
    "    - company name\n",
    "    - company location\n",
    "    - Job summary\n",
    "    - Job posted date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc646de5",
   "metadata": {},
   "source": [
    "##### Finding all job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76f3f0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = soup.find_all('div', {'class':'job_seen_beacon'})\n",
    "len(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04e2239",
   "metadata": {},
   "source": [
    "##### 1st job post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ee8290",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = jobs[0]\n",
    "#first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a29689",
   "metadata": {},
   "source": [
    "##### setting an empty list to fill it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecd074ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbba920d",
   "metadata": {},
   "source": [
    "#### Extract the job title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae6b64c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data Analyst'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title = first.a.span.get('title')\n",
    "job_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269bcd10",
   "metadata": {},
   "source": [
    "#### Extract the company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7396fe77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kotn'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name = first.find('div', 'css-1qv0295 e37uo190').text.strip()\n",
    "company_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73116ad7",
   "metadata": {},
   "source": [
    "#### Extract the company's location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbd1d32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cairo'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_loc = first.find('div', 'css-1p0sjhy eu4oa1w0').text.strip()\n",
    "company_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e513fd",
   "metadata": {},
   "source": [
    "#### Extract the job summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01fe18cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Perform data entry tasks to input new data and update existing records. The Data Analyst will work closely with cross-functional teams to gather required data…'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = first.find('div', 'underShelfFooter').ul.text.replace('\\n',' ').strip()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf101d",
   "metadata": {},
   "source": [
    "#### Extract the job posted date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dada4aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_6852\\871023863.py:1: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  Date_JobPosted = first.find('div', 'underShelfFooter').find('span', 'css-qvloho eu4oa1w0').find_all(text=True, recursive=False)[-1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Posted 30+ days ago'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Date_JobPosted = first.find('div', 'underShelfFooter').find('span', 'css-qvloho eu4oa1w0').find_all(text=True, recursive=False)[-1]\n",
    "Date_JobPosted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40021e9d",
   "metadata": {},
   "source": [
    "#### Extract the job link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c4b7fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/rc/clk?jk=dee90d9d2570a0cd&bb=y2uMcNqrrU1oAXGTd6rLJdGrozpB9LEgvMclSuLTgxnR4wBzAPg9sG3po6i-dQ7syeCLqa0nHpMW_IfHiXrt1d_G38QVIRMu1yxrx1ikxLfGGBjg9ip_4Cr2vVdJoCZ_&xkcb=SoCr67M39gaFxBW2lR0LbzkdCdPP&fccid=20febb5c80e54eb1&vjs=3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_link = first.a.get('href')\n",
    "job_link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2d6f26",
   "metadata": {},
   "source": [
    "# Generalize all extracted data in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8cc1bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_6852\\1615357154.py:25: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  Date_JobPosted = first.find('div', 'underShelfFooter').find('span', 'css-qvloho eu4oa1w0').find_all(text=True, recursive=False)[-1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Data Analyst',\n",
       " 'Kotn',\n",
       " 'Cairo',\n",
       " 'Perform data entry tasks to input new data and update existing records. The Data Analyst will work closely with cross-functional teams to gather required data…',\n",
       " 'Posted 30+ days ago',\n",
       " '/rc/clk?jk=dee90d9d2570a0cd&bb=y2uMcNqrrU1oAXGTd6rLJdGrozpB9LEgvMclSuLTgxnR4wBzAPg9sG3po6i-dQ7syeCLqa0nHpMW_IfHiXrt1d_G38QVIRMu1yxrx1ikxLfGGBjg9ip_4Cr2vVdJoCZ_&xkcb=SoCr67M39gaFxBW2lR0LbzkdCdPP&fccid=20febb5c80e54eb1&vjs=3')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_records(first):\n",
    "    # job title\n",
    "    job_title = first.a.span.get('title')\n",
    "\n",
    "    # company_name\n",
    "    try:\n",
    "        company_name = first.find('div', 'css-1qv0295 e37uo190').text.strip()\n",
    "    except AttributeError:\n",
    "        company_name = 'confidential'\n",
    "        \n",
    "    # company location\n",
    "    try:\n",
    "        company_loc = first.find('div', 'css-1p0sjhy eu4oa1w0').text.strip()\n",
    "    except AttributeError:\n",
    "        company_loc = 'confidential'\n",
    "        \n",
    "    # job summary\n",
    "    try:\n",
    "        summary = first.find('div', 'underShelfFooter').ul.text.replace('\\n',' ').strip()\n",
    "    except AttributeError:\n",
    "        summary = 'Not Found'\n",
    "        \n",
    "    # job postes date  \n",
    "    try:\n",
    "        Date_JobPosted = first.find('div', 'underShelfFooter').find('span', 'css-qvloho eu4oa1w0').find_all(text=True, recursive=False)[-1]\n",
    "    except AttributeError:\n",
    "        Date_JobPosted = 'Not Found'\n",
    "    \n",
    "    # job link\n",
    "    try:\n",
    "        job_link = first.a.get('href')\n",
    "    except AttributeError:\n",
    "        job_link = 'Not Found'\n",
    "        \n",
    "        \n",
    "    \n",
    "    return (job_title, company_name, company_loc, summary, Date_JobPosted, job_link)\n",
    "\n",
    "\n",
    "get_records(first)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7062123",
   "metadata": {},
   "source": [
    "# Extracting data from multiple pages with while loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91d23ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_6852\\1615357154.py:25: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  Date_JobPosted = first.find('div', 'underShelfFooter').find('span', 'css-qvloho eu4oa1w0').find_all(text=True, recursive=False)[-1]\n"
     ]
    }
   ],
   "source": [
    "# setting the link of pagination\n",
    "while True:\n",
    "    try:\n",
    "        url = 'https://eg.indeed.com/' + soup.find('a', {'aria-label':'Next Page'}).get('href')\n",
    "    except AttributeError:\n",
    "        break\n",
    "        \n",
    "    # to acces the url that we'll use for iteration\n",
    "    driver.get(url)\n",
    "    \n",
    "    # getting the html src again for the next iterable pages\n",
    "    src = driver.page_source\n",
    "\n",
    "    # parse the new html src\n",
    "    soup = BeautifulSoup(src, 'html.parser')\n",
    "    \n",
    "    # find all job postings\n",
    "    jobs = soup.find_all('div', {'class':'job_seen_beacon'})\n",
    "\n",
    "    \n",
    "    # begin iteration\n",
    "    for first in jobs:\n",
    "        record = get_records(first)\n",
    "        \n",
    "        records.append(record)\n",
    "        \n",
    "\n",
    "# lastly quit the driver :)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b833b9",
   "metadata": {},
   "source": [
    "# Save the scrapted data into a csv  file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "705b80dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv saved!\n"
     ]
    }
   ],
   "source": [
    "# converts list of records into a dataframe\n",
    "df = pd.DataFrame(records, columns=['job_title', 'company_name', 'company_loc', 'summary', 'Date_JobPosted', 'job_link'])  \n",
    "\n",
    "# save the dataframe into a csv file\n",
    "df.to_csv('indeed_ScrapedData.csv', index=False)\n",
    "\n",
    "print(\"csv saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a078ed08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_loc</th>\n",
       "      <th>summary</th>\n",
       "      <th>Date_JobPosted</th>\n",
       "      <th>job_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Nawy Real Estate</td>\n",
       "      <td>Maadi</td>\n",
       "      <td>Familiarity with data warehouse development an...</td>\n",
       "      <td>Posted 9 days ago</td>\n",
       "      <td>/rc/clk?jk=04231f8f9ac86d40&amp;bb=MnrglTZx347eUYR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Financial Analyst</td>\n",
       "      <td>HES world</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>Prepares reports and analyzes financial data i...</td>\n",
       "      <td>Posted 30+ days ago</td>\n",
       "      <td>/rc/clk?jk=b8c26c745ddbe471&amp;bb=MnrglTZx347eUYR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Workforce Analyst</td>\n",
       "      <td>Majorel Egypt</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>Responsible for reporting data management acti...</td>\n",
       "      <td>Posted 30+ days ago</td>\n",
       "      <td>/rc/clk?jk=384d20e20a0e5259&amp;bb=MnrglTZx347eUYR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Analyst - Data &amp; Analytics - Cairo Airp...</td>\n",
       "      <td>Chalhoub Group</td>\n",
       "      <td>Nasr City</td>\n",
       "      <td>Support analysts and business users across the...</td>\n",
       "      <td>Posted 23 days ago</td>\n",
       "      <td>/rc/clk?jk=e7ed07a200269420&amp;bb=MnrglTZx347eUYR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Procore Technologies</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>We'd love to hear from you if you are a season...</td>\n",
       "      <td>Active 3 days ago</td>\n",
       "      <td>/rc/clk?jk=19c32bbae44cf06e&amp;bb=MnrglTZx347eUYR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>SAP FICO Consultant</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>Experienced in trouble shooting system &amp; data ...</td>\n",
       "      <td>Posted 30+ days ago</td>\n",
       "      <td>/rc/clk?jk=746489eeec598b38&amp;bb=_R6ha8Zlz9WNb7t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Datacenter Transformation Architect</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>New Cairo</td>\n",
       "      <td>Collaborate with financial analysts to ensure ...</td>\n",
       "      <td>Posted 30+ days ago</td>\n",
       "      <td>/rc/clk?jk=4bfeac5f10df87b2&amp;bb=_R6ha8Zlz9WNb7t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Innovation Hub I Cloud Engineering Senior Tech...</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>Experience with data streaming technologies. W...</td>\n",
       "      <td>Posted 30+ days ago</td>\n",
       "      <td>/rc/clk?jk=e70718784d310adb&amp;bb=_R6ha8Zlz9WNb7t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Innovation Hub I Senior Cloud Engineer, Site R...</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>Experience with data streaming technologies. W...</td>\n",
       "      <td>Posted 30+ days ago</td>\n",
       "      <td>/rc/clk?jk=7a4322674aad267b&amp;bb=_R6ha8Zlz9WNb7t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Senior SAP FIN FI Consultant</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>Experienced in trouble shooting system &amp; data ...</td>\n",
       "      <td>Posted 30+ days ago</td>\n",
       "      <td>/rc/clk?jk=068ee692c81e983b&amp;bb=_R6ha8Zlz9WNb7t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             job_title          company_name  \\\n",
       "0                                  Senior Data Analyst      Nawy Real Estate   \n",
       "1                                    Financial Analyst             HES world   \n",
       "2                                    Workforce Analyst         Majorel Egypt   \n",
       "3    Senior Analyst - Data & Analytics - Cairo Airp...        Chalhoub Group   \n",
       "4                                  Senior Data Analyst  Procore Technologies   \n",
       "..                                                 ...                   ...   \n",
       "220                                SAP FICO Consultant                   IBM   \n",
       "221                Datacenter Transformation Architect             Capgemini   \n",
       "222  Innovation Hub I Cloud Engineering Senior Tech...              Deloitte   \n",
       "223  Innovation Hub I Senior Cloud Engineer, Site R...              Deloitte   \n",
       "224                       Senior SAP FIN FI Consultant                   IBM   \n",
       "\n",
       "    company_loc                                            summary  \\\n",
       "0         Maadi  Familiarity with data warehouse development an...   \n",
       "1         Cairo  Prepares reports and analyzes financial data i...   \n",
       "2         Cairo  Responsible for reporting data management acti...   \n",
       "3     Nasr City  Support analysts and business users across the...   \n",
       "4         Cairo  We'd love to hear from you if you are a season...   \n",
       "..          ...                                                ...   \n",
       "220       Cairo  Experienced in trouble shooting system & data ...   \n",
       "221   New Cairo  Collaborate with financial analysts to ensure ...   \n",
       "222       Cairo  Experience with data streaming technologies. W...   \n",
       "223       Cairo  Experience with data streaming technologies. W...   \n",
       "224       Cairo  Experienced in trouble shooting system & data ...   \n",
       "\n",
       "          Date_JobPosted                                           job_link  \n",
       "0      Posted 9 days ago  /rc/clk?jk=04231f8f9ac86d40&bb=MnrglTZx347eUYR...  \n",
       "1    Posted 30+ days ago  /rc/clk?jk=b8c26c745ddbe471&bb=MnrglTZx347eUYR...  \n",
       "2    Posted 30+ days ago  /rc/clk?jk=384d20e20a0e5259&bb=MnrglTZx347eUYR...  \n",
       "3     Posted 23 days ago  /rc/clk?jk=e7ed07a200269420&bb=MnrglTZx347eUYR...  \n",
       "4      Active 3 days ago  /rc/clk?jk=19c32bbae44cf06e&bb=MnrglTZx347eUYR...  \n",
       "..                   ...                                                ...  \n",
       "220  Posted 30+ days ago  /rc/clk?jk=746489eeec598b38&bb=_R6ha8Zlz9WNb7t...  \n",
       "221  Posted 30+ days ago  /rc/clk?jk=4bfeac5f10df87b2&bb=_R6ha8Zlz9WNb7t...  \n",
       "222  Posted 30+ days ago  /rc/clk?jk=e70718784d310adb&bb=_R6ha8Zlz9WNb7t...  \n",
       "223  Posted 30+ days ago  /rc/clk?jk=7a4322674aad267b&bb=_R6ha8Zlz9WNb7t...  \n",
       "224  Posted 30+ days ago  /rc/clk?jk=068ee692c81e983b&bb=_R6ha8Zlz9WNb7t...  \n",
       "\n",
       "[225 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4dedcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
